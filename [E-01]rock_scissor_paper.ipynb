{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da09af4d",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">Exploration_01 인공지능과 가위 바위 보 하기</span>\n",
    "\n",
    "목차\n",
    "1. 데이터 준비\n",
    "2. 딥러닝 네트워크 설계\n",
    "3. 딥러닝 네트워크 학습\n",
    "4. 테스트 데이터로 성능 확인\n",
    "5. 모델 개선 방법\n",
    "6. 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e5081",
   "metadata": {},
   "source": [
    "step 1. 데이터 준비\n",
    "    \n",
    "    - 사전에 teachablemachine.withgoogle.com을 통해서 학습 데이터로 사용될 가위, 바위, 보 사진 300장을 찍어둔다.\n",
    "    - 준비된 학습 데이터 사진을 각 디렉토리에 업로드한다.\n",
    "    - 업로드 된 데이터를 불러오고 Resize 과정을 거쳐준다.(사전에 준비한 이미지의 크기를 28x28로 변경해준다)\n",
    "    - Resize 된 이미지를 가지고 load_data() 함수를 사용해서 라벨링을 해준다.\n",
    "     * 주의사항 : 숫자의 경우는 0~9까지의 10개 클래스가 있지만 가위,바위,보의 경우 3개의 클래스를 가진다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfb7013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 이미지를 Resize 해주는 과정\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\ttarget_size=(28,28) # 이미지의 크기를 28x28로 변경\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\" # 가위 이미지가 저장된 경로를 입력\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b52957c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "주먹 이미지 resized 완료\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"주먹 이미지 resized 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30b5ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resized 완료\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resized 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc408f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수는 300장을 준비했기 때문에 300으로 입력\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화 -> 정규화 과정을 거치치 않으면 어떻게 되는가? / 작동하는가? 작동하지 않는가?\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534c4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[20])\n",
    "print('라벨: ', y_train[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1880f",
   "metadata": {},
   "source": [
    "step 2. 딥러닝 네트워크 설계\n",
    "\n",
    "    - 이번 모델은 tensorflow keras에서 Sequential API라는 방법을 사용함.\n",
    "    - Sequential API방법은 개발의 자유도는 떨어지지만 매우 간단하게 딥러닝 모델을 만들 수 있음.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "905c4fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 30,819\n",
      "Trainable params: 30,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "ch_1=16\n",
    "ch_2=32\n",
    "dense_1=32\n",
    "# 추후 하이퍼파라미터를 변경해서 모델의 성능을 더 향상시킬 수 있다.\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(ch_1, (3,3), activation='relu', input_shape=(28,28,3))) \n",
    "model.add(keras.layers.MaxPool2D(2,2))                  # 흑백이미지의 경우 1, 칼라이미지의 경우 R,G,B 3값을 가지기 때문에 3으로 입력\n",
    "model.add(keras.layers.Conv2D(ch_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(dense_1, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax')) # 우리는 3가지 클래스를 구분하기 때문에 3으로 입력\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d42c502",
   "metadata": {},
   "source": [
    "step 3. 딥러닝 네트워크 학습\n",
    "    \n",
    "    - 만든 네트워크의 입력은 (데이터갯수, 이미지크기 x, 이미지크기 y, 채널수)와 같은 형태를 가진다.\n",
    "    - x_train 학습 데이터를 사용해서 딥러닝 네트워크를 학습시켜준다.\n",
    "    - epochs=10이란 데이터를 10번 반복해서 학습을 시키라는 의미이다.\n",
    "    - 우리는 x_train을 정규화시켰기 때문에 x_train_norm을 입력해주어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61949586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 27s 18ms/step - loss: 1.0933 - accuracy: 0.4033\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.4200\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0541 - accuracy: 0.5467\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0128 - accuracy: 0.5833\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9448 - accuracy: 0.5900\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8599 - accuracy: 0.6733\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7747 - accuracy: 0.7333\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.7800\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.7967\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feba41474f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = 10) # 정규화된 x_train_norm 입력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadad104",
   "metadata": {},
   "source": [
    "    * 인식 정확도가 0.4033부터 마지막에는 0.8133까지 상승하는 것을 확인할 수 있다.\n",
    "    * 질문\n",
    "        - 학습 데이터를 더 추가하면 인식 정확도를 더 향상 시킬 수 있는가?\n",
    "        - 학습 데이터는 많으면 많을수록 정확도를 더 향상시켜주는가?\n",
    "        - 하이퍼파라미터를 수정함으로써 인식 정확도를 더 향상 시킬 수 있는가?\n",
    "        - 그렇다면 최적의 하이퍼파라미터 수치는 몇인가?\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518d0cc",
   "metadata": {},
   "source": [
    "step 4. 테스트 데이터로 성능 확인\n",
    "    \n",
    "    - 위에서 학습시킨 모델을 가지고 테스트 데이터를 이용해서 성능을 확인해볼 수 있다.\n",
    "    - 테스트 데이터도 학습 데이터와 같이 데이터를 디렉토리에 업로드 한 뒤 불러와서 이미지 사이즈를 변경하는 Resize 과정, 넘버링 과정을 거쳐준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12359c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "Test data 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path_1 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "image_dir_path_2 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "image_dir_path_3 = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path_1)\n",
    "resize_images(image_dir_path_2)\n",
    "resize_images(image_dir_path_3)\n",
    "\n",
    "print(\"Test data 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722852ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 정규화 과정\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec59f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.6020 - accuracy: 0.3400\n",
      "test_loss: 1.6020468473434448 \n",
      "test_accuracy: 0.3400000035762787\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84088ba4",
   "metadata": {},
   "source": [
    "    * 테스트 데이터 인식 정확도가 0.34로 학습 데이터 인식 정확도인 0.8167보다 많이 떨어지는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f998cf",
   "metadata": {},
   "source": [
    "setp 5. 모델 개선 방법\n",
    "  \n",
    "  - 하이퍼파라미터 변경을 통한 개선을 기대할 수 있다.\n",
    "  - Conv2D레이어에서 입력 이미지의 턱징 수를 늘리거나 줄여보기\n",
    "  - Dense 레이어에서 뉴런수를 바꿔보기\n",
    "  - epoch를 변경해서 학습 반복 횟수 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc9e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 11ms/step - loss: 1.0938 - accuracy: 0.3933\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0599 - accuracy: 0.5267\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0356 - accuracy: 0.5800\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9772 - accuracy: 0.5933\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8937 - accuracy: 0.6533\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7995 - accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7013 - accuracy: 0.7667\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.7800\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7900\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.8233\n",
      "10/10 - 0s - loss: 1.9345 - accuracy: 0.3167\n",
      "test_loss: 1.934471607208252 \n",
      "test_accuracy: 0.3166666626930237\n"
     ]
    }
   ],
   "source": [
    "#ch_1 을 32로 변경\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "ch_1=32\n",
    "ch_2=32\n",
    "dense_1=32\n",
    "epoch_1 = 10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(ch_1, (3,3), activation='relu', input_shape=(28,28,3))) \n",
    "model.add(keras.layers.MaxPool2D(2,2))                  \n",
    "model.add(keras.layers.Conv2D(ch_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(dense_1, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = epoch_1)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da5584f",
   "metadata": {},
   "source": [
    "  - 첫번째 하이퍼파라미터 변경에서는 Conv2D 레이어에서 입력 이미지의 특징 수를 늘렸는데 정확도는 0.3167로 더 낮아졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8be0209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.1484 - accuracy: 0.3233\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0949 - accuracy: 0.4167\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0674 - accuracy: 0.4067\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0248 - accuracy: 0.5733\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9935 - accuracy: 0.6133\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9184 - accuracy: 0.7067\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8388 - accuracy: 0.6967\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7419 - accuracy: 0.7300\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6594 - accuracy: 0.7833\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6733\n",
      "10/10 - 0s - loss: 1.3818 - accuracy: 0.3333\n",
      "test_loss: 1.3818057775497437 \n",
      "test_accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "# dense의 값을 64로 설정\n",
    "\n",
    "ch_1=16\n",
    "ch_2=32\n",
    "dense_1=64\n",
    "epoch_1 = 10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(ch_1, (3,3), activation='relu', input_shape=(28,28,3))) \n",
    "model.add(keras.layers.MaxPool2D(2,2))                  \n",
    "model.add(keras.layers.Conv2D(ch_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(dense_1, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = epoch_1)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933391cf",
   "metadata": {},
   "source": [
    "  - 두번째 하이퍼파라미터 변경에서는 Dense의 값을 변경해서 뉴런수를 바꾸어보았지만 정확도는 0.3333으로 큰 변화가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24669d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0865 - accuracy: 0.4500\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0708 - accuracy: 0.3933\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0385 - accuracy: 0.5500\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9950 - accuracy: 0.6067\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.9369 - accuracy: 0.6367\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8541 - accuracy: 0.6800\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6684 - accuracy: 0.7900\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5886 - accuracy: 0.7733\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8100\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8200\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8967\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8533\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2522 - accuracy: 0.9500\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9567\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9967\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9867\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9967\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 2.8660 - accuracy: 0.3067\n",
      "test_loss: 2.8660223484039307 \n",
      "test_accuracy: 0.30666667222976685\n"
     ]
    }
   ],
   "source": [
    "# \bepoch 값을 20으로 설정\n",
    "\n",
    "ch_1=16\n",
    "ch_2=32\n",
    "dense_1=32\n",
    "epoch_1 = 20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(ch_1, (3,3), activation='relu', input_shape=(28,28,3))) \n",
    "model.add(keras.layers.MaxPool2D(2,2))                  \n",
    "model.add(keras.layers.Conv2D(ch_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(dense_1, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = epoch_1)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf7f684",
   "metadata": {},
   "source": [
    "  - 세번째 하이퍼파라미터 변경에서는 다른 값들을 초기 값으로 변경하고 학습반복횟수인 epoch 값을 20으로 변경했지만 큰 변화는 없었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7c71d",
   "metadata": {},
   "source": [
    "### 데이터양 늘려서 모델 성능 개선\n",
    "\n",
    "  - 먼저 사용했던 데이터 300개보다 더 많은 각각 600장씩 총 1800장의 데이터를 준비했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e80abfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600  images to be resized.\n",
      "600  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "600  images to be resized.\n",
      "600  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "600  images to be resized.\n",
      "600  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 이미지 resize 작업\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor600/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock600/rock\" # 가위 이미지가 저장된 경로를 입력\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper600/paper\" # 가위 이미지가 저장된 경로를 입력\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4373a790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1800 입니다.\n",
      "x2_train shape: (1440, 28, 28, 3)\n",
      "y2_train shape: (1440,)\n",
      "X2_test shape: (360, 28, 28, 3)\n",
      "y2_test shape: (360,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습데이터와 평가데이터는 사이킷런을 이용해서 8:2 비율로 나누었다.\n",
    "\n",
    "def load_data(img_path, number_of_data=1800): \n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor600/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock600/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper600/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x2, y2)=load_data(image_dir_path)\n",
    "x2_norm = x2/255.0\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(x2_norm, y2, test_size=0.2, random_state=15)\n",
    "\n",
    "\n",
    "print(\"x2_train shape: {}\".format(x2_train.shape))\n",
    "print(\"y2_train shape: {}\".format(y2_train.shape))\n",
    "print(\"X2_test shape: {}\".format(x2_test.shape))\n",
    "print(\"y2_test shape: {}\".format(y2_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8d8607b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 1.0415 - accuracy: 0.4563\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.8199 - accuracy: 0.6347\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7917\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8417\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 0.3085 - accuracy: 0.9049\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.9264\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.9382\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9674\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.9646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea98c43eb0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_1=16\n",
    "ch_2=32\n",
    "dense_1=32\n",
    "epoch_1=10\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(ch_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(ch_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(dense_1, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x2_train, y2_train, epochs=epoch_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8dabaf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 - 0s - loss: 0.1171 - accuracy: 0.9611\n",
      "test_loss: 0.11710114032030106 \n",
      "test_accuracy: 0.9611111283302307\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x2_test,y2_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f05d21",
   "metadata": {},
   "source": [
    "  - 데이터양을 1800장으로 늘렸을때 300장만 가지고 작업했을때보다 정확도가 확연히 많이 오른 것을 확인할 수 있었다.(0.34 -> 0.96으로 상승)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cafd3",
   "metadata": {},
   "source": [
    "step 6. 회고\n",
    "\n",
    "  - 처음하는 Explration이었기 때문에 모든것이 낮설고 어려운 느낌이었다.\n",
    "  - 데이터를 직접 수집하고 그 데이터 전처리 과정을 거쳐야 하는데 데이터 전처리 과정에서 실수가 있으면 찾아내는 것이 꽤 어려웠다.\n",
    "  - 데이터 수집 부분에서는 수집한 사진들이 내림차순이나 오름차순, 혹은 정렬된 파일 이름을 가지고 있어야 하는 줄 알았지만 파일 이름이 아닌 파일의 확장자를 통해서 데이터 처리가 이루어진다는 것을 알게 되었다. 파일이름이 중요한 것이 아닌 파일 확장자가 .jpg가 맞는지가 중요했다.\n",
    "  - 하이퍼파라미터 변경을 통해서도 정확도를 높일 수 있다고 했는데 이번 경우에는 하이퍼파라미터를 변경해도 큰 변화가 없었다.\n",
    "  - 하이퍼파라미터 변경으로 정확도를 올릴 수 있는 케이스는 어떤 경우가 있는지 찾아보는 것도 좋을 것 같다는 생각이 들었다.\n",
    "  - 데이터 수집으로 정확도를 올리는 경우 데이터의 양이 많아질수록 정확도가 높아지는 것 같다.\n",
    "  - 하지만 데이터의 양이 많아지려면 수집하는것도 어렵고 데이터 전처리도 어려워지는 것 같다.\n",
    "  - 사이킷런의 train_test_split 이 데이터를 나누는데 매우 편리하다는 것을 직접 사용해보니까 느낄 수 있었다.\n",
    "  - 마지막으로 직접 코드를 작성할 때 은근 영타 오타가 많이 생겨서 나중에 코드 오류가 생겼을 때 찾기가 어렵기 때문에 처음 작성할 때 주의해서 작성해야 할 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
